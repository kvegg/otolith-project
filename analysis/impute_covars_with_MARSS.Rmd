---
title: "Imputation of missing covariates for use in modeling growth rates of juvenile Chinook salmon"
output:
  pdf_document:
    highlight: haddock
fontsize: 11pt
geometry: margin=1in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\vspace{0.2in}

[__Mark Scheuerell__](https://faculty.washington.edu/scheuerl/)\footnote{Present address: USGS Washington Cooperative Fish and Wildlife Research Unit, School of Aquatic and Fishery Sciences, University of Washington, Seattle, WA}  
_Fish Ecology Division, Northwest Fisheries Science Center, Seattle, WA_

\vspace{0.1in}

__Karl Veggerby__  
_Ocean Associates, Seattle, WA_

\vspace{0.2in}

This is version `r paste0('0.',format(Sys.time(), '%y.%m.%d'))`.


# Background

We would like to examine temperature as a possible covariate in the analyses of the growth data. However, the temperature are not complete for all sites and times, and therefore we have to impute some of the values based upon measurements from two different sources: Team Carcass and Team Tagging. To do so, we will use the __MARSS__ package, which is designed to fit autoregressive models to multivariate time series data.

Specifically, we have data from $n$ = 7 streams and 1-2 sources for each stream. For temperature measured at site $i$ from source $j$ on day $d$ ($T_{i,j,d}$), we can write

\begin{equation}
  \label{eq1}
  \begin{gathered}
    \mathbf{T}_{d} = \mathbf{Z} \mathbf{x}_{d} + \mathbf{a} + \mathbf{v}_{d} \\
    \mathbf{x}_{d} = \mathbf{B} \mathbf{x}_{d-1} + \mathbf{C} \mathbf{c}_{d-h} + \mathbf{w}_{d},
  \end{gathered}
\end{equation}

where $\mathbf{T}_{d}$ is an $n \times 1$ vector of the $T_{i,j,d}$ and $\mathbf{x}_{d}$ is an $m \times 1$ vector of the true, but unobserved temperature in each stream on day $d$. Here, $m < n$ because we have 2 sources of data from some streams. The vectors of observation ($\mathbf{v}_{d}$) and process ($\mathbf{w}_{d}$) errors are both distributed as multivariate normal with means $\mathbf{0}$ and covariance matrices $\mathbf{R}$ and $\mathbf{Q}$, respectively.

The specific forms for $\mathbf{Z}$, $\mathbf{a}$ and $\mathbf{B}$ will be chosen initially based on visually identified shared/different characteristics among the different sites. The values in the matrix $\mathbf{C}$ determine the effect(s) of any potential, and possibly lagged, covariates contained in $\mathbf{c}_{d-h}$. Those will also be chosen after inspection of the data from the different sources


# Requirements

```{r load_pkgs, message=FALSE}
## for analysis
library(MARSS)
## for plotting
library(viridisLite)
## for dir mgmt
library(here)
datadir <- here("data")
analdir <- here("analysis")
```

# Data munging

We begin by loading the data file with the temperature summaries by time (rows) and location (cols).

```{r load_covars}
## load obs covariates
cobs <- read.csv(file.path(datadir, "daily_mean_temp_2.csv"),
                 stringsAsFactors = FALSE)
## inspect data
head(cobs)
```

Let's simplify some names in the file and round the observations to the nearest 0.01.

```{r change_colnames}
## simplify colnames
colnames(cobs) <- gsub("data_source", replacement = "s", x = colnames(cobs))
colnames(cobs) <- gsub("daily_mean", replacement = "T", x = colnames(cobs))
## site abbrevs
sites <- sort(gsub("T_", replacement = "", x = colnames(cobs)[10:16]))
## re-arrange cols
cn <- c(colnames(cobs)[1:2], paste0("s_",sites), paste0("T_",sites))
cobs <- cobs[,cn]
## simplify sources
cobs[cobs=="team carcass"] <- "car"
cobs[cobs=="achord_gordy"] <- "tag"
## round temps
cobs[,grep("T_", colnames(cobs))] <- round(cobs[,grep("T_", colnames(cobs))], 2)
```

The temperature data come from two different sources:

  1. the food web group (Sanderson et al.), and  
  2. the juvenile tagging group (Achord, Axel et al.).  
  
We need to split the data out by those groups.

```{r split_obs_grps}
## empty data frames
car <- tag <- matrix(NA, nrow(cobs), length(sites),
                     dimnames = list(NULL, sites))
## measurements
vals <- cobs[,-(1:9)]
## indices of data type
i_car <- cobs[,3:9] == "car"
i_tag <- cobs[,3:9] == "tag"
## group-specific data
car[i_car] <- vals[i_car]
tag[i_tag] <- vals[i_tag]
## drop any sites with all NA's
car <- car[,apply(car, 2, function(x) !all(is.na(x)))]
colnames(car) <- paste0(colnames(car), "_car")
tag <- tag[,apply(tag, 2, function(x) !all(is.na(x)))]
colnames(tag) <- paste0(colnames(tag), "_tag")
## regroup by sites & source
cobs_m <- cbind(car, tag)
cobs_m <- cobs_m[,sort(colnames(cobs_m))]
## remove tailing rows with all NA
all_na <- apply(apply(cobs_m, 1, is.na), 2, all)
cobs_m <- cobs_m[!all_na,]
```

# Plot the data

## All sites together

```{r data_plot, fig.align="center", echo = FALSE}
par(mai=c(0.9,0.9,0.1,0.1), omi=c(0,0,0,0))
## plot the data
matplot(cobs_m, type = "l", lty = "solid",
        lwd = 2, las = 1,
        ylab = "Temperature (C)", xaxt="n",
        col = plasma(ncol(cobs_m), alpha = 0.5, begin = 0, end = 1))
years <- unique(cobs$year)
n_yrs <- length(years)
n_days <- nrow(cobs) / n_yrs
axis(side = 1,
     at = seq(n_days / 2, by = n_days, length.out = n_yrs),
     labels = years,
     tick = FALSE, line = -1,
     cex.axis = 0.7)
```

\pagebreak

## By site

```{r plot_by_site, fig.height=9, fig.width=7, fig.align="center", echo = FALSE}
par(mfrow = c(length(sites), 1),
    mai = c(0.3,0.4,0.2,0.1),
    omi = c(0,0,0,0))
for(i in sites) {
  ## site-specific data
  tmp <- cobs_m[, grep(i, colnames(cobs_m)), drop = FALSE]
  ## plot the data
  matplot(tmp, type = "l", lty = "solid",
          lwd = 2, las = 1,
          ylab = "Temperature (C)", xaxt="n", main = i,
          col = plasma(ncol(tmp), alpha = 1, begin = 0.1, end = 0.3))
  axis(side = 1,
       at = seq(n_days / 2, by = n_days, length.out = n_yrs),
       labels = years,
       tick = FALSE, line = -1)
}
```

# Imputation

Based on the plots above, we will use the following forms for the vectors and matrices in Eqn (\ref{eq1}) that relate the states to themselves and the observations to the states. Specifically, it looks as though the seasonal patterns dominate in each stream, with very little evidence for an increasing or decreasing trend. Furthermore, other than subtle changes in the overall level (mean), the streams appear to move up and down in synchrony. Thus, we will set

* $\mathbf{Z}$ equal to an $n \times 1$ column vector of 1's ($[1~1\dots1]^{\top}$), such that all of the data are assumed to be observations of a single overall temperature regime;

* $\mathbf{a}$ equal to an $n \times 1$ column vector where the elements are shared for data from the same stream (_e.g._, both sets of data for Elk would get the same level, but Elk is different from Valley);

* $\mathbf{v}_d \sim \text{MVN}(\mathbf{0}, \mathbf{R})$ with $\mathbf{R}$ equal to an $n \times n$ matrix with the same variance ($r$) in each element of the diagonal and 0's elsewhere,

$$
\mathbf{R} = 
  \begin{bmatrix}
  r & 0 & \dots & 0 \\
  0 & r & \dots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \dots & r \\
  \end{bmatrix};
$$

* $\mathbf{B}$ equal to an $m \times m$ matrix with different parameters down the diagonal and 0's elsewhere, which will allow the true temperature in each stream to follow a first-order autoregressive process,

$$
\mathbf{B} = 
  \begin{bmatrix}
  b_1 & 0 & \dots & 0 \\
  0 & b_2 & \dots & 0 \\
  \vdots & \vdots & \ddots & \vdots \\
  0 & 0 & \dots & b_m \\
  \end{bmatrix};
$$

* $\mathbf{C}$ equal to an $m \times 1$ vector with unique parameters to allow for varying effects of the seasonal signal on each stream ($[C_1 ~ C_2 \dots C_m]^{\top}$);

* $\mathbf{c}$ equal to a discrete cosine wave with a period of ~`r round(nrow(cobs) / (n_yrs - 0.5), 0)` days, such that $\mathbf{c}_t$ is a scalar; and

* $\mathbf{w}_d \sim \text{MVN}(\mathbf{0}, \mathbf{Q})$ with $\mathbf{Q}$ equal to an $m \times m$ matrix with the same variance ($q$) in each element of the diagonal and the same covariance ($p$) elsewhere,

$$
\mathbf{Q} = 
  \begin{bmatrix}
  q & p & \dots & p \\
  p & q & \dots & p \\
  \vdots & \vdots & \ddots & \vdots \\
  p & p & \dots & q \\
  \end{bmatrix}.
$$

# MARSS modeling

Now we can translate our model from Eqn (\ref{eq1}) into a form suitable for `MARSS()`.

## Observation equation

We begin with the observation equation.

```{r marss_obs}
## number of data sets
nn <- dim(cobs_m)[2]
## number of streams
mm <- length(sites)
## empty list for model defn
mod_list <- list()
## Z
# ZZ <- matrix(1, nrow = nn, ncol = 1)
ZZ <- matrix(0, nrow = nn, ncol = mm)
for(i in seq(mm)) {
  ZZ[which(gsub("_.*", "", colnames(cobs_m)) %in% sites[i]),i] <- 1
}
mod_list$Z <- ZZ
## a
aa <- matrix(list(0), nrow = nn, ncol = 1)
aa[,] <- gsub("_.*", "", colnames(cobs_m))
mod_list$A <- aa
## R
RR <- matrix(list(0), nrow = nn, ncol = nn)
diag(RR) <- rep("r", nn)
mod_list$R <- RR
```

## Process equation

And now the process (state) equation.

```{r marss_proc}
## B
BB <- matrix(list(0), nrow = mm, ncol = mm)
diag(BB) <- sites
mod_list$B <- BB
## u
mod_list$U <- matrix(0, nrow = mm, ncol = 1)
## Q
QQ <- matrix(list("p"), nrow = mm, ncol = mm)
diag(QQ) <- rep("q", mm)
mod_list$Q <- QQ
```

## Fit a base model with no seasonal forcing

```{r fit_base_model}
## fit base model (if not already saved)
if(!file.exists(file.path(analdir, "base_temp_model.rds"))) {
  fit_base <- MARSS(y = t(cobs_m), model = mod_list, control = list(maxit = 2000))
  ## save results to file
  saveRDS(fit_base, file.path(analdir, "base_temp_model.rds"))
}
```

Let's examine the model fits.

```{r examine_base_model}
fit_base <- readRDS(file.path(analdir, "base_temp_model.rds"))
fit_base
```

## Fit random-walk models

The estimates of the diagonal values of the matrix $\mathbf{B}$ from the above model, which control the degree of autocorrelation from one time step to another, are very close to 1. This suggests we should try a subtely different model where we fix $\mathbf{B}$ equal to the identity matrix $\mathbf{I}$.

```{r fit_base_rw}
## change B in model defn
mod_list$B <- diag(mm)
## fit model
if(!file.exists(file.path(analdir, "rw_temp_model.rds"))) {
  fit_rw <- MARSS(y = t(cobs_m), model = mod_list, control = list(maxit = 2000))
  ## save results to file
  saveRDS(fit_rw, file.path(analdir, "rw_temp_model.rds"))
}
```

Let's examine the model fits.

```{r examine_rw_model}
fit_rw <- readRDS(file.path(analdir, "rw_temp_model.rds"))
fit_rw
```

Interestingly, this model does not fit as well (based on an $\Delta$AIC value of ~90 units).

## Base model with seasonal signal

Now let's add a seasonal effect in the form of a discrete cosine wave. By adjusting the period correctly, we can make it reflect the observed seasonal pattern.

```{r cosine_wave, fig.height=4, fig.width=7, fig.align="center", echo = FALSE}
## proper "yearly" interval (days)
intvl <- nrow(cobs_m) / (n_yrs - 0.5)
## discrete cosine wave
cc <- -cos(2 * pi * seq(nrow(cobs_m)) / intvl)
par(mai=c(0.9,0.9,0.1,0.1), omi=c(0,0,0,0))
plot.ts(cc, ylab = "Cosine", xaxt="n", las = 1)
axis(side = 1,
     at = seq(n_days / 2, by = intvl, length.out = n_yrs),
     labels = years,
     tick = FALSE, line = -1,
     cex.axis = 0.7)
```

\vspace{0.25in}

```{r fit_seasonal_model}
## C
mod_list$C <- matrix(sites, nrow = mm, ncol = 1)
## c (discrete sine wave)
mod_list$c <- matrix(cc, nrow = 1)
## change B back to diagonal and unequal
mod_list$B <- BB
## fit model
if(!file.exists(file.path(analdir, "seas_temp_model.rds"))) {
  fit_seas <- MARSS(y = t(cobs_m), model = mod_list, control = list(maxit = 2000))
  ## save results to file
  saveRDS(fit_seas, file.path(analdir, "seas_temp_model.rds"))
}
```

Let's examine the model fits.

```{r examine_seas_model}
fit_seas <- readRDS(file.path(analdir, "seas_temp_model.rds"))
fit_seas
```

## De-mean the observations

The lack of convergence and low values for $\mathbf{a}$ (_i.e._, `A.???` in the `MARSS()` output) suggests we should instead de-mean the observations, fits the model, and then add the mean back to the estimates. We'll also exclude the cosine wave for now.

```{r demean_base}
## de-mean obs
dm_obs <- scale(cobs_m, center = TRUE, scale = FALSE)
## set a = 0
mod_list$A <- matrix(0, nrow = nn, ncol = 1)
## fit model
if(!file.exists(file.path(analdir, "dbase_temp_model.rds"))) {
  fit_dbase <- MARSS(y = t(dm_obs), model = mod_list, control = list(maxit = 2000))
  ## save results to file
  saveRDS(fit_dbase, file.path(analdir, "dbase_temp_model.rds"))
}
```

```{r examine_dbase_model}
fit_dbase <- readRDS(file.path(analdir, "dbase_temp_model.rds"))
fit_dbase
```

That didn't work as well as hoped.

## Scale the observations

Now we'll try to fully scale the observations, such that times series for each location has zero mean and unit variance. In addition, we will assume all of the locations are observations of a single, regional temperature patter, but scaled accordingly at the localed level (_i.e._, different min, max, mean).

To make this work within a location, we need to combine the multiple time series into one.

```{r scaled_base}
## means by location
scld <- matrix(NA, ncol = length(sites), nrow = dim(cobs_m)[1])
colnames(scld) <- sites
## average fitted values by site
for(i in sites) {
  ## site-specific data
  tmp <- cobs_m[, grep(i, colnames(cobs_m)), drop = FALSE]
  if(dim(tmp)[2] != 1) {
    scld[,i] <- apply(tmp, 1, mean, na.rm = TRUE)
  } else
    scld[,i] <- tmp
}

## de-mean obs
sc_obs <- scale(scld)
## all locations are obs of single state
mod_list$Z <- matrix(1, nrow = length(sites), ncol = 1)
mod_list$A <- matrix(0, nrow = length(sites), ncol = 1)
RR <- matrix(list(0), nrow = length(sites), ncol = length(sites))
diag(RR) <- rep("r", length(sites))
mod_list$R <- RR
## set scalars for state eqn
mod_list$B <- matrix("b")
mod_list$U <- matrix(0)
mod_list$Q <- matrix("q")
mod_list$C <- matrix("C")
## fit model
if(!file.exists(file.path(analdir, "sbase_temp_model.rds"))) {
  fit_sbase <- MARSS(y = t(sc_obs), model = mod_list, control = list(maxit = 2000))
  ## save results to file
  saveRDS(fit_sbase, file.path(analdir, "sbase_temp_model.rds"))
}
```

```{r examine_sbase_model}
fit_sbase <- readRDS(file.path(analdir, "sbase_temp_model.rds"))
fit_sbase
```

```{r dbase_plot, fig.align="center", echo = FALSE}
par(mai=c(0.9,0.9,0.1,0.1), omi=c(0,0,0,0))
## plot the data
matplot(sc_obs, type = "l", lty = "solid",
        lwd = 2, las = 1,
        ylab = "Scaled temperature (C)", xaxt="n",
        col = plasma(ncol(sc_obs), alpha = 0.5, begin = 0, end = 1))
lines(seq(nrow(scld)), fit_sbase$states, lwd = 2, col = "gray")
axis(side = 1,
     at = seq(n_days / 2, by = n_days, length.out = n_yrs),
     labels = years,
     tick = FALSE, line = -1,
     cex.axis = 0.7)
```

## Estimated temperature by site

```{r est_by_site, fig.height=9, fig.width=7, fig.align="center"}
y_hat_Z <- t(fit_sbase$ytT)
colnames(y_hat_Z) <- sites

## plot fitted values
par(mfrow = c(length(sites), 1),
    mai = c(0.3,0.4,0.2,0.1),
    omi = c(0,0,0,0))
for(i in sites) {
  ## plot the data
  plot.ts(y_hat_Z[,i], type = "l", lty = "solid",
          lwd = 2, las = 1,
          ylab = "Scaled temperature (C)", xaxt="n", main = i,
          col = plasma(ncol(tmp), alpha = 0.5, begin = 0.1, end = 0.3))
  axis(side = 1,
       at = seq(n_days / 2, by = n_days, length.out = n_yrs),
       labels = years,
       tick = FALSE, line = -1)
}
```


# Reconstruction

The last step is to transform these z-scored values back into normal space.

```{r recon_back, fig.height=9, fig.width=7, fig.align="center"}
## mean and var of orig series
men <- apply(scld, 2, mean, na.rm = TRUE)
std <- apply(scld, 2, sd, na.rm = TRUE)

y_hat <- y_hat_Z
for(i in 1:length(sites)) {
  y_hat[,i] <- y_hat_Z[,i] * std[i] + men[i]
}

## plot fitted values
par(mfrow = c(length(sites), 1),
    mai = c(0.3,0.4,0.2,0.1),
    omi = c(0,0,0,0))
for(i in sites) {
  ## plot the data
  plot.ts(y_hat[,i], type = "l", lty = "solid",
          lwd = 2, las = 1,
          ylab = "Temperature (C)", xaxt="n", main = i,
          col = plasma(ncol(tmp), alpha = 0.5, begin = 0.1, end = 0.3))
  axis(side = 1,
       at = seq(n_days / 2, by = n_days, length.out = n_yrs),
       labels = years,
       tick = FALSE, line = -1)
}
```

These values look reasonable, so we'll round them and save them as an __R__ object and a csv.

```{r save_recon}
y_hat_rnd <- round(y_hat, 2)
saveRDS(y_hat_rnd, file.path(analdir, "reconstructed_temps.rds"))
write.csv(y_hat_rnd, file = file.path(datadir, "reconstructed_temps.csv"), row.names = FALSE)
```







